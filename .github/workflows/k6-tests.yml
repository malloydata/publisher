name: k6 Tests

on:
  pull_request:
    branches: [main]
  push:
    branches: [main]
  workflow_dispatch:

jobs:
  k6_tests:
    name: k6 Tests
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          submodules: "true" # Fetch submodules

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: "20"

      - name: Install Bun
        uses: oven-sh/setup-bun@v2
        with:
          bun-version: 1.2.23

      - name: Cache Bun dependencies
        id: bun-cache
        uses: actions/cache@v4
        with:
          path: ~/.bun/install/cache
          key: ${{ runner.os }}-bun-${{ hashFiles('**/bun.lock') }}
          restore-keys: |
            ${{ runner.os }}-bun-

      - name: Build server
        run: |
          echo "Bun cache hit: ${{ steps.bun-cache.outputs.cache-hit }}"
          bun install --frozen-lockfile
          bun run build
        env:
          BUN_CONFIG_SKIP_POSTINSTALL_SCRIPTS: "1"

      - name: Link local package
        run: |
          cd packages/server && npm link

      - name: Install k6-tests dependencies
        run: |
          cd packages/server/k6-tests
          bun install --frozen-lockfile

      - name: Generate k6 API clients
        run: |
          cd packages/server/k6-tests
          bun run generate-clients

      - name: Clone malloy-samples
        run: |
          cd packages/server/k6-tests
          bun run clone-malloy-samples

      - name: Setup k6
        uses: grafana/setup-k6-action@v1

      - name: Setup BigQuery credentials
        run: |
          if [ -z "$BQ_PRESTO_TRINO_KEY" ]; then
            echo "BQ_PRESTO_TRINO_KEY is not set"
            exit 1
          fi

          # Detect base64 vs JSON
          if echo "$BQ_PRESTO_TRINO_KEY" | grep -qE '^\s*eyJ'; then
            echo "Detected Base64 credentials. Decoding..."
            echo "$BQ_PRESTO_TRINO_KEY" | base64 --decode > /tmp/bq-credentials.json
          else
            echo "Detected raw JSON credentials."
            echo "$BQ_PRESTO_TRINO_KEY" > /tmp/bq-credentials.json
          fi

          # Validate JSON
          jq . /tmp/bq-credentials.json > /dev/null

          # Export for rest of job
          echo "GOOGLE_APPLICATION_CREDENTIALS=/tmp/bq-credentials.json" >> $GITHUB_ENV

          echo "BigQuery credentials file created at /tmp/bq-credentials.json"
        env:
          BQ_PRESTO_TRINO_KEY: ${{ secrets.BQ_PRESTO_TRINO_KEY }}


      - name: Start CPU monitoring
        run: |
          mkdir -p /tmp/cpu-monitoring
          # Start background CPU monitoring script
          cat > /tmp/cpu-monitoring/monitor.sh << 'EOF'
          #!/bin/bash
          echo "timestamp,pid,%cpu,%mem,rss_mb,vsz_mb,command" > /tmp/cpu-monitoring/cpu_usage.csv
          echo "timestamp,cpu_total%,mem_total_mb,mem_used_mb,mem_free_mb,mem_available_mb,load_avg" > /tmp/cpu-monitoring/system_metrics.csv

          while true; do
            timestamp=$(date -u +"%Y-%m-%dT%H:%M:%SZ")

            # Monitor malloy-publisher process and related Node.js/Bun processes
            # Match: malloy-publisher, node processes running malloy, bun processes, k6 processes
            ps aux | grep -E "malloy-publisher|node.*malloy|bun.*malloy|k6 run" | grep -v grep | while read line; do
              # Parse ps output: USER PID %CPU %MEM RSS VSZ TTY STAT START TIME COMMAND
              pid=$(echo "$line" | awk '{print $2}')
              cpu=$(echo "$line" | awk '{print $3}')
              mem=$(echo "$line" | awk '{print $4}')
              rss=$(echo "$line" | awk '{print $6}')
              vsz=$(echo "$line" | awk '{print $5}')
              # Convert RSS and VSZ from KB to MB
              rss_mb=$(echo "$rss" | awk '{printf "%.2f", $1/1024}')
              vsz_mb=$(echo "$vsz" | awk '{printf "%.2f", $1/1024}')
              # Get command (everything from column 11 onwards)
              cmd=$(echo "$line" | awk '{for(i=11;i<=NF;i++) printf "%s ", $i; print ""}' | sed 's/ *$//')
              echo "$timestamp,$pid,$cpu,$mem,$rss_mb,$vsz_mb,$cmd" >> /tmp/cpu-monitoring/cpu_usage.csv
            done

            # System-wide metrics
            # Memory metrics (most reliable)
            mem_info=$(free -m | grep Mem)
            mem_total=$(echo "$mem_info" | awk '{print $2}')
            mem_used=$(echo "$mem_info" | awk '{print $3}')
            mem_free=$(echo "$mem_info" | awk '{print $4}')
            mem_available=$(echo "$mem_info" | awk '{print $7}')

            # CPU metrics - sum of all process CPU usage (approximation)
            cpu_total=$(ps aux | awk 'NR>1 {sum+=$3} END {printf "%.2f", sum}')

            # Load average
            load_avg=$(cat /proc/loadavg | awk '{print $1","$2","$3}')

            echo "$timestamp,$cpu_total,$mem_total,$mem_used,$mem_free,$mem_available,$load_avg" >> /tmp/cpu-monitoring/system_metrics.csv

            sleep 5
          done
          EOF
          chmod +x /tmp/cpu-monitoring/monitor.sh
          /tmp/cpu-monitoring/monitor.sh &
          echo $! > /tmp/cpu-monitoring/monitor.pid
          echo "CPU monitoring started (PID: $(cat /tmp/cpu-monitoring/monitor.pid))"
        continue-on-error: true

      - name: Start npx server
        run: |
          cd packages/server && npx malloy-publisher --port 4002 --server_root ./ &
          SERVER_PID=$!
          echo "SERVER_PID=$SERVER_PID" >> $GITHUB_ENV
          echo "Server PID: $SERVER_PID"
          sleep 12
          # Verify server is running
          response=$(curl -s http://localhost:4002/api/v0/projects || echo "failed")
          if [ "$response" = "failed" ]; then
            echo "Server failed to start"
            exit 1
          fi
          echo "Response Data: $response"

          response=$(curl -s -w "\nHTTP_STATUS:%{http_code}" http://localhost:4002/api/v0/projects/malloy-samples/connections/bigquery/schemas)
          status_code=$(echo "$response" | grep "HTTP_STATUS:" | cut -d: -f2)
          data=$(echo "$response" | grep -v "HTTP_STATUS:")
          if [ ${#data} -eq 0 ]; then
            echo "Error: Response data is empty"
            exit 1
          fi
          echo "Status Code: $status_code"
          echo "Server is running on port 4002"
        env:
          GOOGLE_APPLICATION_CREDENTIALS: ${{ env.GOOGLE_APPLICATION_CREDENTIALS }}
          DISABLE_RESPONSE_LOGGING: true

      # Smoke test runs for 1 minute total with 5 virtual users
      - name: Run k6 smoke test
        run: |
          mkdir -p /tmp/k6-results
          cd packages/server/k6-tests
          k6 run \
            --out json=/tmp/k6-results/smoke-test-results.json \
            smoke-test/smoke-test.ts \
            2>&1 | tee /tmp/k6-results/smoke-test-summary.txt
        env:
          K6_PUBLISHER_URL: "http://localhost:4002"
          K6_PROJECT_NAME: "malloy-samples"
          GOOGLE_APPLICATION_CREDENTIALS: ${{ env.GOOGLE_APPLICATION_CREDENTIALS }}

      # Load test runs for 7 minutes total: 1 min ramp-up to 50 virtual users → 5 min sustained load with 50 virtual users → 1 min ramp-down to 0 virtual users
      - name: Run k6 load test
        run: |
          mkdir -p /tmp/k6-results
          cd packages/server/k6-tests
          k6 run \
            --out json=/tmp/k6-results/load-test-results.json \
            load-test/load-test.ts \
            2>&1 | tee /tmp/k6-results/load-test-summary.txt
        env:
          K6_PUBLISHER_URL: "http://localhost:4002"
          K6_PROJECT_NAME: "malloy-samples"
          GOOGLE_APPLICATION_CREDENTIALS: ${{ env.GOOGLE_APPLICATION_CREDENTIALS }}

      - name: Stop CPU monitoring and collect data
        if: always()
        run: |
          # Stop monitoring script
          if [ -f /tmp/cpu-monitoring/monitor.pid ]; then
            MONITOR_PID=$(cat /tmp/cpu-monitoring/monitor.pid)
            if ps -p $MONITOR_PID > /dev/null 2>&1; then
              kill $MONITOR_PID || true
              echo "CPU monitoring stopped"
            fi
          fi

          # Wait a moment for final writes
          sleep 2

          # Generate summary statistics
          if [ -f /tmp/cpu-monitoring/cpu_usage.csv ]; then
            echo "=== CPU Usage Summary ===" > /tmp/cpu-monitoring/cpu_summary.txt
            echo "" >> /tmp/cpu-monitoring/cpu_summary.txt

            # Calculate average CPU usage (skip header and empty lines)
            # CSV format: timestamp,pid,%cpu,%mem,rss_mb,vsz_mb,command
            awk -F',' 'NR>1 && $3!="" && $3+0 == $3 {
              cpu_sum+=$3
              mem_sum+=$4
              rss_sum+=$5
              count++
            }
            END {
              if (count > 0) {
                printf "Average CPU Usage: %.2f%%\n", cpu_sum/count
                printf "Average Memory Usage: %.2f%%\n", mem_sum/count
                printf "Average RSS Memory: %.2f MB\n", rss_sum/count
                printf "Total Samples: %d\n", count
              }
            }' /tmp/cpu-monitoring/cpu_usage.csv >> /tmp/cpu-monitoring/cpu_summary.txt

            echo "" >> /tmp/cpu-monitoring/cpu_summary.txt
            echo "=== Peak CPU Usage ===" >> /tmp/cpu-monitoring/cpu_summary.txt
            awk -F',' 'NR>1 && $3!="" && $3+0 == $3 {print $3}' /tmp/cpu-monitoring/cpu_usage.csv | sort -rn | head -5 | \
              awk '{printf "Peak %d: %.2f%%\n", NR, $1}' >> /tmp/cpu-monitoring/cpu_summary.txt

            echo "" >> /tmp/cpu-monitoring/cpu_summary.txt
            echo "=== Peak Memory Usage ===" >> /tmp/cpu-monitoring/cpu_summary.txt
            awk -F',' 'NR>1 && $4!="" && $4+0 == $4 {print $4}' /tmp/cpu-monitoring/cpu_usage.csv | sort -rn | head -5 | \
              awk '{printf "Peak %d: %.2f%%\n", NR, $1}' >> /tmp/cpu-monitoring/cpu_summary.txt

            echo "" >> /tmp/cpu-monitoring/cpu_summary.txt
            echo "=== System-Wide Metrics Summary ===" >> /tmp/cpu-monitoring/cpu_summary.txt
            if [ -f /tmp/cpu-monitoring/system_metrics.csv ]; then
              awk -F',' 'NR>1 && $2!="" && $2+0 == $2 {
                cpu_total_sum+=$2
                mem_used_sum+=$4
                mem_free_sum+=$5
                count++
              }
              END {
                if (count > 0) {
                  printf "Average System CPU Usage: %.2f%%\n", cpu_total_sum/count
                  printf "Average Memory Used: %.2f MB\n", mem_used_sum/count
                  printf "Average Memory Free: %.2f MB\n", mem_free_sum/count
                }
              }' /tmp/cpu-monitoring/system_metrics.csv >> /tmp/cpu-monitoring/cpu_summary.txt
            fi

            echo "" >> /tmp/cpu-monitoring/cpu_summary.txt
            echo "=== Process CPU Usage Sample (first 20 lines) ===" >> /tmp/cpu-monitoring/cpu_summary.txt
            head -20 /tmp/cpu-monitoring/cpu_usage.csv >> /tmp/cpu-monitoring/cpu_summary.txt

            cat /tmp/cpu-monitoring/cpu_summary.txt
          else
            echo "CPU usage data file not found"
          fi
        continue-on-error: true

      - name: Upload CPU monitoring data
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: cpu-monitoring-data
          path: |
            /tmp/cpu-monitoring/cpu_usage.csv
            /tmp/cpu-monitoring/system_metrics.csv
          retention-days: 30
        continue-on-error: true

      - name: Upload CPU summary
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: cpu-monitoring-summary
          path: /tmp/cpu-monitoring/*.txt
          retention-days: 30
        continue-on-error: true

      - name: Extract k6 summary metrics
        if: always()
        run: |
          mkdir -p /tmp/k6-results

          # Extract final summary from JSON for smoke test
          if [ -f /tmp/k6-results/smoke-test-results.json ]; then
            echo "=== Smoke Test Summary Metrics ===" > /tmp/k6-results/smoke-test-metrics.txt
            jq -r '
              .root_group.checks as $checks |
              .root_group.http_req_duration as $duration |
              .root_group.http_reqs as $reqs |
              .root_group.iterations as $iterations |
              .root_group.vus as $vus |
              "
              HTTP Requests: \($reqs.count) (\($reqs.rate) req/s)
              Iterations: \($iterations.count) (\($iterations.rate) iter/s)
              Virtual Users: \($vus.value) (min: \($vus.min), max: \($vus.max))
              HTTP Request Duration:
                - Average: \($duration.avg)ms
                - Min: \($duration.min)ms
                - Max: \($duration.max)ms
                - Median: \($duration.med)ms
                - P90: \($duration."p(90)")ms
                - P95: \($duration."p(95)")ms
              Checks: \($checks.rate * 100)% passed (\($checks.passes)/\($checks.count))
              HTTP Request Failed: \(.root_group.http_req_failed.rate * 100)%
              Data Received: \(.root_group.data_received.count) (\(.root_group.data_received.rate))
              Data Sent: \(.root_group.data_sent.count) (\(.root_group.data_sent.rate)
              "
            ' /tmp/k6-results/smoke-test-results.json >> /tmp/k6-results/smoke-test-metrics.txt 2>/dev/null || echo "Could not extract smoke test metrics from JSON"
          fi

          # Extract final summary from JSON for load test
          if [ -f /tmp/k6-results/load-test-results.json ]; then
            echo "" >> /tmp/k6-results/load-test-metrics.txt
            echo "=== Load Test Summary Metrics ===" >> /tmp/k6-results/load-test-metrics.txt
            jq -r '
              .root_group.checks as $checks |
              .root_group.http_req_duration as $duration |
              .root_group.http_reqs as $reqs |
              .root_group.iterations as $iterations |
              .root_group.vus as $vus |
              "
              HTTP Requests: \($reqs.count) (\($reqs.rate) req/s)
              Iterations: \($iterations.count) (\($iterations.rate) iter/s)
              Virtual Users: \($vus.value) (min: \($vus.min), max: \($vus.max))
              HTTP Request Duration:
                - Average: \($duration.avg)ms
                - Min: \($duration.min)ms
                - Max: \($duration.max)ms
                - Median: \($duration.med)ms
                - P90: \($duration."p(90)")ms
                - P95: \($duration."p(95)")ms
              Checks: \($checks.rate * 100)% passed (\($checks.passes)/\($checks.count))
              HTTP Request Failed: \(.root_group.http_req_failed.rate * 100)%
              Data Received: \(.root_group.data_received.count) (\(.root_group.data_received.rate))
              Data Sent: \(.root_group.data_sent.count) (\(.root_group.data_sent.rate)
              "
            ' /tmp/k6-results/load-test-results.json >> /tmp/k6-results/load-test-metrics.txt 2>/dev/null || echo "Could not extract load test metrics from JSON"
          fi

          # Display extracted metrics
          if [ -f /tmp/k6-results/load-test-metrics.txt ]; then
            cat /tmp/k6-results/load-test-metrics.txt
          fi
        continue-on-error: true

      - name: Upload k6 test summaries
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: k6-test-summaries
          path: |
            /tmp/k6-results/smoke-test-summary.txt
            /tmp/k6-results/load-test-summary.txt
            /tmp/k6-results/smoke-test-metrics.txt
            /tmp/k6-results/load-test-metrics.txt
          retention-days: 30
        continue-on-error: true

      - name: Upload k6 JSON results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: k6-test-results-json
          path: |
            /tmp/k6-results/smoke-test-results.json
            /tmp/k6-results/load-test-results.json
          retention-days: 30
        continue-on-error: true
